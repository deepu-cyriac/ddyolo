{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
      "Requirement already satisfied: torch==1.8.1+cu111 in d:\\apps\\anaconda\\lib\\site-packages (1.8.1+cu111)\n",
      "Requirement already satisfied: torchvision==0.9.1+cu111 in d:\\apps\\anaconda\\lib\\site-packages (0.9.1+cu111)\n",
      "Requirement already satisfied: torchaudio===0.8.1 in d:\\apps\\anaconda\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\apps\\anaconda\\lib\\site-packages (from torch==1.8.1+cu111) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in d:\\apps\\anaconda\\lib\\site-packages (from torch==1.8.1+cu111) (1.20.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in d:\\apps\\anaconda\\lib\\site-packages (from torchvision==0.9.1+cu111) (8.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.2.2 in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 4)) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 5)) (1.20.3)\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 6)) (4.5.5.64)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 7)) (8.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 8)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 9)) (2.26.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 10)) (1.7.1)\n",
      "Requirement already satisfied: torch>=1.7.0 in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 11)) (1.8.1+cu111)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 12)) (0.9.1+cu111)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 13)) (4.62.3)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 16)) (2.8.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 20)) (1.3.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 21)) (0.11.2)\n",
      "Requirement already satisfied: thop in d:\\apps\\anaconda\\lib\\site-packages (from -r requirements.txt (line 37)) (0.0.31.post2005241907)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\apps\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\apps\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\apps\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\apps\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\apps\\anaconda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\apps\\anaconda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\apps\\anaconda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\apps\\anaconda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.2)\n",
      "Requirement already satisfied: typing-extensions in d:\\apps\\anaconda\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.10.0.2)\n",
      "Requirement already satisfied: colorama in d:\\apps\\anaconda\\lib\\site-packages (from tqdm>=4.41.0->-r requirements.txt (line 13)) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\apps\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\apps\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\apps\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\apps\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (2.0.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\apps\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\apps\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in d:\\apps\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.44.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in d:\\apps\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.20.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\apps\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (2.6.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\apps\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (58.0.4)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\apps\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\apps\\anaconda\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 20)) (2021.3)\n",
      "Requirement already satisfied: six in d:\\apps\\anaconda\\lib\\site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\apps\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\apps\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\apps\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\apps\\anaconda\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\apps\\anaconda\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\apps\\anaconda\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\apps\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\apps\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!cd yolov5 & pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\deepu/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-4-17 torch 1.8.1+cu111 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.5 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoShape(\n",
       "  (model): DetectMultiBackend(\n",
       "    (model): Model(\n",
       "      (model): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Conv(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (4): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (6): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): Conv(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (8): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): SPPF(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (10): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (11): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (12): Concat()\n",
       "        (13): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (15): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (16): Concat()\n",
       "        (17): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (19): Concat()\n",
       "        (20): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (21): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (22): Concat()\n",
       "        (23): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (24): Detect(\n",
       "          (m): ModuleList(\n",
       "            (0): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Real Time Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Make detections \n",
    "    results = model(frame)\n",
    "    \n",
    "    cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid   # Unique identifier\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('data', 'images') #/data/images\n",
    "labels = ['awake', 'drowsy']\n",
    "number_imgs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for awake\n",
      "Collecting images for awake, image number 0\n",
      "Collecting images for awake, image number 1\n",
      "Collecting images for awake, image number 2\n",
      "Collecting images for awake, image number 3\n",
      "Collecting images for awake, image number 4\n",
      "Collecting images for awake, image number 5\n",
      "Collecting images for awake, image number 6\n",
      "Collecting images for awake, image number 7\n",
      "Collecting images for awake, image number 8\n",
      "Collecting images for awake, image number 9\n",
      "Collecting images for awake, image number 10\n",
      "Collecting images for awake, image number 11\n",
      "Collecting images for awake, image number 12\n",
      "Collecting images for awake, image number 13\n",
      "Collecting images for awake, image number 14\n",
      "Collecting images for awake, image number 15\n",
      "Collecting images for awake, image number 16\n",
      "Collecting images for awake, image number 17\n",
      "Collecting images for awake, image number 18\n",
      "Collecting images for awake, image number 19\n",
      "Collecting images for drowsy\n",
      "Collecting images for drowsy, image number 0\n",
      "Collecting images for drowsy, image number 1\n",
      "Collecting images for drowsy, image number 2\n",
      "Collecting images for drowsy, image number 3\n",
      "Collecting images for drowsy, image number 4\n",
      "Collecting images for drowsy, image number 5\n",
      "Collecting images for drowsy, image number 6\n",
      "Collecting images for drowsy, image number 7\n",
      "Collecting images for drowsy, image number 8\n",
      "Collecting images for drowsy, image number 9\n",
      "Collecting images for drowsy, image number 10\n",
      "Collecting images for drowsy, image number 11\n",
      "Collecting images for drowsy, image number 12\n",
      "Collecting images for drowsy, image number 13\n",
      "Collecting images for drowsy, image number 14\n",
      "Collecting images for drowsy, image number 15\n",
      "Collecting images for drowsy, image number 16\n",
      "Collecting images for drowsy, image number 17\n",
      "Collecting images for drowsy, image number 18\n",
      "Collecting images for drowsy, image number 19\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Loop through labels\n",
    "for label in labels:\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(7)\n",
    "    \n",
    "    # Loop through image range\n",
    "    for img_num in range(number_imgs):\n",
    "        print('Collecting images for {}, image number {}'.format(label, img_num))\n",
    "        \n",
    "        # Webcam feed\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Naming out image path\n",
    "        imgname = os.path.join(IMAGES_PATH, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "        \n",
    "        # Writes out image to file \n",
    "        cv2.imwrite(imgname, frame)\n",
    "        \n",
    "        # Render to the screen\n",
    "        cv2.imshow('Image Collection', frame)\n",
    "        \n",
    "        # 2 second delay between captures\n",
    "        time.sleep(3)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\images\\awake.0f518d4c-be7a-11ec-9359-f85ea0e86ebb.jpg\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(IMAGES_PATH, labels[0]+'.'+str(uuid.uuid1())+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'labelImg' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tzutalin/labelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyqt5 in d:\\apps\\anaconda\\lib\\site-packages (5.15.6)\n",
      "Requirement already satisfied: lxml in d:\\apps\\anaconda\\lib\\site-packages (4.8.0)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.8 in d:\\apps\\anaconda\\lib\\site-packages (from pyqt5) (12.10.1)\n",
      "Requirement already satisfied: PyQt5-Qt5>=5.15.2 in d:\\apps\\anaconda\\lib\\site-packages (from pyqt5) (5.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyqt5 lxml --upgrade\n",
    "!cd labelImg && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=dataset.yml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=500, batch_size=16, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=2, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "From https://github.com/ultralytics/yolov5\n",
      "   014acde..7926afc  master              -> origin/master\n",
      "   68bfb5b..1b0b992  test/conv_reduction -> origin/test/conv_reduction\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m YOLOv5 is out of date by 3 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\deepu\\Desktop\\YOLO-Drowsiness-Detection-main\\yolov5\\train.py\", line 667, in <module>\n",
      "    main(opt)\n",
      "  File \"C:\\Users\\deepu\\Desktop\\YOLO-Drowsiness-Detection-main\\yolov5\\train.py\", line 537, in main\n",
      "    check_file(opt.data), check_yaml(opt.cfg), check_yaml(opt.hyp), str(opt.weights), str(opt.project)  # checks\n",
      "  File \"C:\\Users\\deepu\\Desktop\\YOLO-Drowsiness-Detection-main\\yolov5\\utils\\general.py\", line 422, in check_file\n",
      "    assert len(files), f'File not found: {file}'  # assert file was found\n",
      "AssertionError: File not found: dataset.yml\n"
     ]
    }
   ],
   "source": [
    "!cd yolov5 && python train.py --img 320 --batch 16 --epochs 500 --data dataset.yml --weights yolov5s.pt --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Load Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\deepu/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2022-4-17 torch 1.8.1+cu111 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "[Errno 2] No such file or directory: 'yolov5\\\\runs\\\\train\\\\exp15\\\\weights\\\\last.pt'. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpretrained\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mchannels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDetectMultiBackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# download/load FP32 model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[1;31m# model = models.experimental.attempt_load(path, map_location=device)  # download/load FP32 model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, weights, device, dnn, data, fp16)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# PyTorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattempt_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# model stride\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\experimental.py\u001b[0m in \u001b[0;36mattempt_load\u001b[1;34m(weights, map_location, inplace, fuse)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mckpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattempt_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[0mckpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ema'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mckpt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# FP32 model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yolov5\\\\runs\\\\train\\\\exp15\\\\weights\\\\last.pt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4700/1601075308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ultralytics/yolov5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'custom'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'yolov5/runs/train/exp15/weights/last.pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Apps\\Anaconda\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(repo_or_dir, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[0mrepo_or_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_cache_or_reload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anaconda\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[1;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[0mentry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhubconf_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py\u001b[0m in \u001b[0;36mcustom\u001b[1;34m(path, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcustom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'path/to/model.pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m# YOLOv5 custom or local model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautoshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mhelp_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://github.com/ultralytics/yolov5/issues/36'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{e}. Cache may be out of date, try `force_reload=True` or see {help_url} for help.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: [Errno 2] No such file or directory: 'yolov5\\\\runs\\\\train\\\\exp15\\\\weights\\\\last.pt'. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help."
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp15/weights/last.pt', force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = os.path.join('data', 'images', 'awake.c9a24d48-e1f6-11eb-bbef-5cf3709bbcc6.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Make detections \n",
    "    results = model(frame)\n",
    "    \n",
    "    cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
